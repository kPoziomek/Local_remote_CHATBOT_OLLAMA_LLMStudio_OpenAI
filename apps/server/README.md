###

## This is a simple Node.js + Express server

To run Agents locally, you need to run server.js.
Yo need to have a LMStudio running in the same network.

e.g on "http://127.0.0.1:1234/v1", you can access LmStudio API.



### AiSDK runs on normal openAI endpoint 
to use it you need to have a valid openAI API key.
recommended to use .env file to store the key.

### Ollama runs on normal ollama sdk
to use it you need to have ollama running on your machine with models installed.






